{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivations\n",
    "\n",
    "Linear algebra and matrices are a fundamental aspect of data science models and problems, including image processing, deep learning, NLP, and PCA. You will encounter matrices _many_ times in your career as a data scientist!\n",
    "\n",
    "### Steal your archrival's thunder!\n",
    "\n",
    "For now, the goal is to beat your archrival to the punch. You overheard him say that the secret to pre-processing some image for machine learning is to solve a system of equations.\n",
    "\n",
    "Here's the set of equations that you spotted on your rival's screen:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "2 & -1 & 4 & 6 & 3 \\\\\n",
    "4 & 7 & 1 & 1 & 12 \\\\\n",
    "9 & 14 & 2 & 2 & 6 \\\\\n",
    "1 & 1 & 1 & 2 & 17 \\\\\n",
    "-3 & -2 & -6 & 12 & -5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4 \\\\\n",
    "x_5\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "15 \\\\\n",
    "20 \\\\\n",
    "2 \\\\\n",
    "-6\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "How can we solve this system quickly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning with Plain Old Algebra\n",
    "\n",
    "Let's start with a one-variable \"system\" before moving on to two-, three-, or many-variable systems.\n",
    "\n",
    "Suppose we start with a one-variable system like $2X = 10$.\n",
    "\n",
    "How do we solve this?\n",
    "\n",
    "Now consider a two-variable system:\n",
    "\n",
    "$2X + 4Y = 10 \\\\\n",
    "X + 4Y = 7$\n",
    "\n",
    "### Solution through Substitution\n",
    "We _could_ solve this system by taking the first equation, solving it for X, and then plugging the result into the second:\n",
    "\n",
    "$2X + 4Y = 10$. <br/> Thus: $\\\\ 2X = 10 - 4Y \\\\ X = 5 - 2Y$.\n",
    "\n",
    "Plugging in to the second equation, we have:\n",
    "\n",
    "$5 - 2Y + 4Y = 7$. <br/> Thus: $\\\\ 5 + 2Y = 7 \\\\ 2Y = 2 \\\\ Y = 1$.\n",
    "\n",
    "Plugging this back into the first equation, we have:\n",
    "\n",
    "$2X + 4 = 10$.  <br/> Thus: $\\\\ 2X = 6 \\\\ X = 3$.\n",
    "\n",
    "And we have our solutions:  $X = 3, Y = 1$.\n",
    "\n",
    "But this is computationally _very slow_! There is a better way:\n",
    "\n",
    "### Solution through Elimination\n",
    "\n",
    "Much faster is to subtract the second equation from the first:\n",
    "\n",
    "If $2X + 4Y = 10$ and $X + 4Y = 7$,\n",
    "then $(2X - X) + (4Y - 4Y) = 10 - 7$, i.e. $X = 3$. Then I could subtract this ($X + 0Y = 3$) from $X + 4Y = 7$, yielding: $4Y = 4$, i.e. $Y = 1$.\n",
    "\n",
    "We can represent this in matrix form using the equations as our rows. The columns will correspond to the variables:\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "2 & 4 & 10 \\\\\n",
    "1 & 4 & 7\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\rightarrow \\begin{bmatrix}\n",
    "1 & 0 & 3 \\\\\n",
    "1 & 4 & 7\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\rightarrow \\begin{bmatrix}\n",
    "1 & 0 & 3 \\\\\n",
    "0 & 4 & 4\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\rightarrow \\begin{bmatrix}\n",
    "1 & 0 & 3 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "This is the matrix way of saying that X = 3 and that Y = 1.\n",
    "\n",
    "There are lots of strategies in linear algebra for \"reducing\" a matrix to a form where there are ones down the main diagonal and zeroes everywhere else (except the rightmost column), because such a matrix represents a list of \"already solved\" equations: <br/>\n",
    "$X_1 + 0X_2 + ... + 0X_n = b_1 \\\\\n",
    "0X_1 + X_2 + 0X_3 + ... + 0X_n = b_2 \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "0X_1 + ... + 0X_{n-1} + X_n = b_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scalars to Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _scalar_ has simply a single value. Any real number can be the value of a scalar.\n",
    "\n",
    "A _vector_ must be specified by _two_ parameters: magnitude and direction. In a Cartesian coordinate system, a vector $\\vec{v}$ will generally be specified by its x- and y-components, $v_x$ and $v_y$.\n",
    "\n",
    "In that case: <br/>\n",
    "    \\- The magnitude of $v$ is given by $||v|| = \\sqrt{v^2_x + v^2_y}$ <br/>\n",
    "    \\- The direction of $v$ is given by $\\theta = tan^{-1}\\left(\\frac{v_y}{v_x}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Addition\n",
    "\n",
    "Vector addition is simple: Just add the x- and the y-components together:\n",
    "\n",
    "$(8, 14) + (7, 6) = (15, 20)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 20])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Code it!\n",
    "\n",
    "# Consider the vectors (8, 14) and (7, 6). Let's try using Python\n",
    "# to add them together.\n",
    "\n",
    "vec_1 = (8, 14)\n",
    "vec_2 = (7, 6)\n",
    "\n",
    "vec_1 + vec_2 == (15, 20) #Result is False \n",
    "\n",
    "np.array(vec_1) + np.array(vec_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? Check with a partner to make sure you understand how Python interpreted our code here. Why did we use '==' instead of '='?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.all>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try typing 'vec_1.' and then pressing TAB. What options do we have here?\n",
    "\n",
    "vec_1.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Python is not particularly good for non-scalar arithmetic. This is one of many places where NumPy can come in very handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 20])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try this again, but this time we'll use NumPy arrays:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vec_1, vec_2 = np.array([8, 14]), np.array([7, 6])\n",
    "vec_1 + vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is base Python any better for vector _multiplication_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multiplying the vectors (4, 14) and (8, 6)):\n",
    "\n",
    "# vec_1 = (4, 14)\n",
    "# vec_2 = (8, 6)\n",
    "\n",
    "# vec_1 * vec_2\n",
    "#No this does not work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? Why did we get an error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact there are multiple ways of understanding the notion of vector multiplication. All are potentially useful, but the one that we'll likely be of most use is the *dot-product*, which is defined as follows:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "\\end{bmatrix}\n",
    ". \n",
    "\\begin{bmatrix}\n",
    "c \\\\\n",
    "d\n",
    "\\end{bmatrix}\n",
    "=\n",
    "ac + bd\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot-product is the sum of the pariwise products of the vectors' entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we've got the vectors stored as NumPy arrays, let's once again\n",
    "# try typing 'vec_1.' and then pressing TAB.\n",
    "\n",
    "# Now we have many options! Notice that one of these options is 'dot'.\n",
    "# This is our dot-product!\n",
    "\n",
    "vec_1.dot(vec_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .dot() method to calculate the dot-product of our two vectors:\n",
    "\n",
    "# Your code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Products\n",
    "\n",
    "The cross-product is defined for two- and three-dimensional vectors.\n",
    "\n",
    "Cross-multiplying vectors is much like multiplying polynomials: Each component of each vector must be multipled by each component of the other  vector. The extra bit to remember is how the cross products of the unit vectors work:\n",
    "\n",
    "Typically we write:\n",
    "\n",
    "$\\hat{i}$: the unit vector in the x-direction <br/>\n",
    "$\\hat{j}$: the unit vector in the y-direction <br/>\n",
    "$\\hat{k}$: the unit vector in the z-direction\n",
    "\n",
    "**The cross-product of each unit vector with itself is 0.**\n",
    "\n",
    "Also:\n",
    "\n",
    "$\\large\\hat{i}\\times\\hat{j} = \\hat{k}$ <br/>\n",
    "$\\large\\hat{j}\\times\\hat{k} = \\hat{i}$ <br/>\n",
    "$\\large\\hat{k}\\times\\hat{i} = \\hat{j}$\n",
    "\n",
    "Order matters! If we multiply in the other direction, we get (-) signs:\n",
    "\n",
    "$\\large\\hat{j}\\times\\hat{i} = -\\hat{k}$ <br/>\n",
    "$\\large\\hat{k}\\times\\hat{j} = -\\hat{i}$ <br/>\n",
    "$\\large\\hat{i}\\times\\hat{k} = -\\hat{j}$\n",
    "\n",
    "In general, the product vector of two vectors is _orthogonal_ to the plane determined by those two vectors.\n",
    "\n",
    "**Examples**:\n",
    "\n",
    "- $(2, 3)\\times(4, 5) = (2\\hat{i} + 3\\hat{j})\\times(4\\hat{i} + 5\\hat{j}) \\\\ = (2)(4)(\\hat{i}\\times\\hat{i}) + (2)(5)(\\hat{i}\\times\\hat{j}) + (3)(4)(\\hat{j}\\times\\hat{i}) + (3)(5)(\\hat{j}\\times\\hat{j}) \\\\= 10\\hat{k} - 12\\hat{k} \\\\= -2\\hat{k}$\n",
    "<br/>\n",
    "\n",
    "- $(3, 4, 5)\\times(-1, -2, -1) = (3\\hat{i} + 4\\hat{j} + 5\\hat{k})\\times(-\\hat{i} -2\\hat{j} -\\hat{k}) \\\\= \\hat{i}(-4 + 10) + \\hat{j}(-5 + 3) + \\hat{k}(-6 + 4) \\\\= 6\\hat{i} - 2\\hat{j} -2\\hat{k}$\n",
    "\n",
    "You can use ```numpy.cross()``` for the cross-product of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use ```numpy.cross()``` to calculate the cross-product of\n",
    "# (2, 3) and (3, 5). Does the answer make sense to you?\n",
    "\n",
    "vec_1 = np.array([2,3])\n",
    "vec_2 = np.array([3,5])\n",
    "\n",
    "np.cross(vec_1, vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, -5,  1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use ```numpy.cross()``` to calculate the cross-product of\n",
    "# (2, 3, 1) and (3, 5, 4). Does the answer make sense to you?\n",
    "\n",
    "vec_a = np.array([2,3,1])\n",
    "vec_b = np.array([3,5,4])\n",
    "\n",
    "np.cross(vec_a,vec_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Dimensions: From Vectors to Matrices\n",
    "\n",
    "For higher dimensions we can use _matrices_ to express ourselves. Suppose we had a two-variable system:\n",
    "\n",
    "\\begin{align}\n",
    "a_{1,1}x_1 + a_{1,2}x_2 = c_1 \\\\\n",
    "a_{2,1}x_1 + a_{2,2}x_2 = c_2\n",
    "\\end{align}\n",
    "\n",
    "We can write this as:\n",
    "\n",
    "$A\\vec{x} = \\vec{c}$,\n",
    "\n",
    "where now $\\vec{x}$ is the _vector_ $(x_1, x_2)$ and $\\vec{c}$ is the _vector_ $(c_1, c_2)$.\n",
    "\n",
    "Similarly, $A$ is the _matrix_ of coefficients that describe our system:\n",
    "\\begin{equation} A = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "c_2\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Ways to Multiply\n",
    "\n",
    "Just as there were different notions of \"multiplication\" for vectors, so too there are different notions of multiplication for matrices.\n",
    "\n",
    "### Hadamard Product\n",
    "The Hadamard product, for example, is analogous to matrix addition, and proceeds element-wise:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\circ\n",
    "\\begin{bmatrix}\n",
    "b_{1,1} & b_{1,2} \\\\\n",
    "b_{2,1} & b_{2,2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{1,1}\\times b_{1,1} & a_{1,2}\\times b_{1,2} \\\\\n",
    "a_{2,1}\\times b_{2,1} & a_{2,2}\\times b_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that Hadamard multiplication requires that the matrices being multiplied have the same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  8],\n",
       "       [ 5, 18]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Hadamard product is very easy in NumPy: Just use *!\n",
    "\n",
    "# Use NumPy to calculate the Hadamard product of\n",
    "# [[1, 2], [1, 2]] and [[3, 4], [5, 9]]\n",
    "\n",
    "# Your code here!\n",
    "\n",
    "mat_a = np.array([[1,2],[1,2]])\n",
    "mat_b = np.array([[3,4],[5,9]])\n",
    "\n",
    "mat_a * mat_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot-Product\n",
    "Very often when people talk about multiplying matrices they'll mean the dot-product:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "b_{1,1} & b_{1,2} \\\\\n",
    "b_{2,1} & b_{2,2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{1,1}\\times b_{1,1} + a_{1,2}\\times b_{2,1} \\\\\n",
    "a_{2,1}\\times b_{1,2} + a_{2,2}\\times b_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Take the entries in each _row_ of the left matrix and multiply them, respectively, by the entries in each _column_ of the right matrix, and then add them up. This is the product we calculated above with our two vectors!\n",
    "\n",
    "Note that matrix dot-multiplication is NOT commutative! In general, $AB \\neq BA$.\n",
    "\n",
    "#### A note about vectors and matrices\n",
    "\n",
    "Strictly speaking, this is true for vectors as well. Above, we multiplied the _row_-vector $(a, b)$ by the _column_-vector $(c, d)$. A row-vector is simply a matrix with only one row; a column-vector is simply a matrix with only one column. What would be the result of multiplying the column-vector $(c, d)$ on the left by the row-vector $(a, b)$ on the right?\n",
    "\n",
    "Ans.:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "c \\\\\n",
    "d\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "a & b\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "ca & cb \\\\\n",
    "da & db\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "#### End of note\n",
    "\n",
    "Observe also that in order to be able to perform the dot product on two matrices A and B, the number of columns of A must equal the number of rows of B.\n",
    "\n",
    "Also, the number of rows of the _product_ matrix will equal the number of rows of A, and the number of columns of the product matrix will equal the number of columns of B.\n",
    "\n",
    "In order to solve an equation like $A\\vec{x} = \\vec{c}$ for $\\vec{x}$, we can't very well divide $\\vec{c}$ by $A$! But there is a notion of matrix _inversion_ that is relevant here, which is analogous to multiplicative inversion. If we have an equation like $2x = 10$, we can simply multiply both sides by the multiplicative inverse of the coefficient of $x$, viz. $2^{-1}$. And here the point, of course, is that $2^{-1} \\times 2 = 1$.\n",
    "\n",
    "In the higher-dimensional case, what we can do is to left-multiply both sides by the _inverse matrix_ of A, denoted $A^{-1}$, and here the point is that the dot-product $A^{-1}A = I$, where $I$ is the identity matrix containing 1's along the main diagonal (upper-left to lower-right) and 0's everywhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NumPy arrays, dot-multiply the matrices\n",
    "\\begin{bmatrix}\n",
    "3 & 2 \\\\\n",
    "5 & 7\n",
    "\\end{bmatrix}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{bmatrix}\n",
    "2 & 4 \\\\\n",
    "3 & 10\n",
    "\\end{bmatrix}\n",
    "\n",
    "in the code-cell below. Remember that you need square brackets around the whole array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 32],\n",
       "       [31, 90]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here!\n",
    "\n",
    "mat_1 = np.array([[3,2],[5,7]])\n",
    "mat_2 = np.array([[2,4],[3,10]])\n",
    "\n",
    "mat_1.dot(mat_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Sometimes you will encounter _tensors_ in your work. A tensor is to a matrix as a matrix is to a vector. A vector has one representational dimension and a matrix has two. If you need an object with three or more representational dimensions, you're talking about a tensor. A tensor has rows (that run from left to right), columns (that run from top to bottom), and _tubes_ (that run from front to back)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Data Science Problems\n",
    "\n",
    "Consider a typical dataset and the associated multiple linear regression problem. We have many observations (rows), each of which consists of a set of values both for the predictors (columns, i.e. the independent variables) and for the target (the dependent variable).\n",
    "\n",
    "We can think of the values of the independent variables as our matrix $A$ of coefficients and of the values of the dependent variable as our output vector $\\vec{c}$.\n",
    "\n",
    "The task here is, in effect, to solve for $\\vec{\\beta}$, where we have that $A\\vec{\\beta} = \\vec{c}$, except in general we'll have more rows than columns. This is why we won't in general be computing matrix inverses. (They're computationally expensive, anyway.) This is also why we have a problem requiring not a direct solution but rather an optimization--in our case, a best-fit line.\n",
    "\n",
    "Using $z$ for our independent variables and $y$ for our dependent variable, we have:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_1\\begin{bmatrix}\n",
    "z_{1,1} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "z_{m,1}\n",
    "\\end{bmatrix} +\n",
    "... + \\beta_n\\begin{bmatrix}\n",
    "z_{1,n} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "z_{m,n}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    "y_m\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy to Solve a System of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy's ```linalg``` module has a ```.solve()``` method that you can use to solve a system of linear equations!\n",
    "\n",
    "In particular, it will solve for the vector $\\vec{x}$ in the equation $A\\vec{x} = b$. You should know that, \"under the hood\", the ```.solve()``` method does NOT compute the inverse matrix $A^{-1}$. Check out this discussion on stackoverflow for a helpful discussion: https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check out the documentation for ```.solve()``` here: https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!\n",
    "\n",
    "# Use the .solve() method to solve your rival's system and\n",
    "# steal his thunder!\n",
    "\n",
    "X = np.array([[2,-1,4,6,3], [4,7,1,1,12],\n",
    "            [9,14,2,2,6], [1,1,1,2,17],\n",
    "            [-3,-2,-6,12,-5]])\n",
    "\n",
    "y = np.array([3,15,20,2,-6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.51240389,   9.46394893,   8.31031481,   1.49992746,\n",
       "        -0.2506891 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Broadcasting\n",
    "\n",
    "If you try to do arithmetic with differently sized arrays, NumPy will actually replicate the smaller array in order to perform the operation. Read about broadcasting here: https://machinelearningmastery.com/broadcasting-with-numpy-arrays/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
